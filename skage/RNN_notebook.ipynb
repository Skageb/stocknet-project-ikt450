{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initalise dataset and config object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization fitting done for feature Sentiment\n",
      "Normalization fitting done for feature Twitter_Volume\n",
      "Normalization fitting done for feature Movement_Percent\n",
      "Normalization fitting done for feature Open\n",
      "Normalization fitting done for feature High\n",
      "Normalization fitting done for feature Low\n",
      "Normalization fitting done for feature Volume\n",
      "Normalization fitting done for feature Sentiment\n",
      "Normalization fitting done for feature Twitter_Volume\n",
      "Normalization fitting done for feature Movement_Percent\n",
      "Normalization fitting done for feature Open\n",
      "Normalization fitting done for feature High\n",
      "Normalization fitting done for feature Low\n",
      "Normalization fitting done for feature Volume\n",
      "Normalization fitting done for feature Sentiment\n",
      "Normalization fitting done for feature Twitter_Volume\n",
      "Normalization fitting done for feature Movement_Percent\n",
      "Normalization fitting done for feature Open\n",
      "Normalization fitting done for feature High\n",
      "Normalization fitting done for feature Low\n",
      "Normalization fitting done for feature Volume\n"
     ]
    }
   ],
   "source": [
    "from config import cfg\n",
    "from dataset_loaders import TweetXPriceY, SentimentPriceXPriceY\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = cfg.dataloader(\n",
    "    start_date=cfg.train_start_date,\n",
    "    end_date=cfg.train_end_date,\n",
    "    **cfg.dataset_loader_args\n",
    ")\n",
    "eval_data = cfg.dataloader(\n",
    "    start_date=cfg.eval_start_date,\n",
    "    end_date=cfg.eval_end_date,\n",
    "    **cfg.dataset_loader_args\n",
    ")\n",
    "\n",
    "test_data = cfg.dataloader(\n",
    "    start_date=cfg.test_start_date,\n",
    "    end_date=cfg.test_end_date,\n",
    "    **cfg.dataset_loader_args\n",
    ")\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=cfg.BATCH_SIZE, num_workers=cfg.num_workers, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_data, batch_size=cfg.BATCH_SIZE, num_workers=cfg.num_workers,shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=cfg.BATCH_SIZE, num_workers=cfg.num_workers,shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "inspect_dataset = False\n",
    "if inspect_dataset:\n",
    "        for batch_idx, (x, y) in enumerate(tqdm(train_dataloader)):\n",
    "                input(f'Length train set: {train_data.__len__()}, Length Eval set: {eval_data.__len__()}')\n",
    "                print(f\"Sentiment batch shape: {x[0].size()}\")\n",
    "                print(f\"Price Feature batch shape: {x[1].size()}\")\n",
    "                print(f\"Labels batch shape: {y.size()}\")\n",
    "                print(x[0], x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class RNN_simple(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(RNN_simple, self).__init__()\n",
    "        #self.embedding = nn.Embedding(cfg.vocab_size, embedding_dim=50)\n",
    "        self.rnn = nn.RNN(input_size=cfg.dataset_loader_args['tweets_per_day']*cfg.dataset_loader_args['words_per_tweet'], hidden_size=cfg.rnn_hidden_size, num_layers=cfg.rnn_hidden_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(cfg.rnn_hidden_size, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = self.embedding(x)\n",
    "        h0 = torch.zeros(cfg.rnn_hidden_layers, x.size(0), cfg.rnn_hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out[:, -1, :]  # Use the output from the last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "class RNN_simple_v2(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(RNN_simple, self).__init__()\n",
    "        #self.embedding = nn.Embedding(cfg.vocab_size, embedding_dim=50)\n",
    "        self.rnn = nn.RNN(input_size=cfg.dataset_loader_args['tweets_per_day']*cfg.dataset_loader_args['words_per_tweet'], hidden_size=cfg.rnn_hidden_size, num_layers=cfg.rnn_hidden_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(cfg.rnn_hidden_size, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = self.embedding(x)\n",
    "        h0 = torch.zeros(cfg.rnn_hidden_layers, x.size(0), cfg.rnn_hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out[:, -1, :]  # Use the output from the last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class LSTM_v1(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(LSTM_v1, self).__init__()\n",
    "        #self.embedding = nn.Embedding(cfg.vocab_size, embedding_dim=50)\n",
    "        self.embedding = nn.Embedding(cfg.vocab_size, embedding_dim=128, padding_idx=0)\n",
    "        #self.rnn = nn.LSTM(input_size=cfg.dataset_loader_args['tweets_per_day']*cfg.dataset_loader_args['words_per_tweet'], hidden_size=cfg.rnn_hidden_size, num_layers=cfg.rnn_hidden_layers, batch_first=True)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=128,  # Embedding dimension\n",
    "            hidden_size=cfg.rnn_hidden_size, \n",
    "            num_layers=cfg.rnn_hidden_layers, \n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(cfg.rnn_hidden_size, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        x = self.embedding(x)  # Shape: (batch_size, seq_length, embedding_dim)\n",
    "        out, _ = self.lstm(x)  # Shape: (batch_size, seq_length, hidden_size)\n",
    "        out = self.dropout(out[:, -1, :])  # Use the output from the last time step\n",
    "        out = self.fc(out)  # Shape: (batch_size, 2)\n",
    "        return out  # Raw logits\n",
    "    \n",
    "\n",
    "from inital_models import Depth_First_GRU2\n",
    "from models import GRU_Shallow_1fc_AntiOverfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def evaluate_model(dataloader, model):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_logits = []\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, y) in enumerate(tqdm(dataloader)):\n",
    "            if isinstance(x, list):\n",
    "                x = [t.to(device) for t in x]\n",
    "                x = [t.float() for t in x]\n",
    "                y = y.to(device)\n",
    "            else:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "                x = x.float()\n",
    "                    #x = x.view(x.size(0), x.size(1), -1)  # Ensure input shape is (batch_size, seq_length, input_size)\n",
    "                x = x.view(x.size(0), -1)\n",
    "\n",
    "            outputs = model(x).squeeze()\n",
    "\n",
    "            outputs = model(x)  # Outputs are raw logits of shape (batch_size, num_classes)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            \n",
    "\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "\n",
    "            # Collect data for debugging\n",
    "            all_logits.append(outputs.cpu())\n",
    "            all_preds.append(predicted.cpu())\n",
    "            all_targets.append(y.cpu())\n",
    "\n",
    "    accuracy = correct / total\n",
    "\n",
    "    #print(f'Accuracy: {accuracy:.4f}%')\n",
    "\n",
    "    # Concatenate all the collected and transform to numpy array\n",
    "    y_hat_logits = torch.cat(all_logits).numpy()\n",
    "    y_hat = torch.cat(all_preds).numpy()\n",
    "    y = torch.cat(all_targets).numpy()\n",
    "\n",
    "    return  accuracy, y, y_hat, y_hat_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:14<00:00, 43.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Average Loss: 0.7010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 35.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5162%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:03<00:00, 31.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5378%\n",
      "Train Accuracy: 0.5019948487450129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:18<00:00, 33.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/60], Average Loss: 0.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:02<00:00, 28.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5284%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:03<00:00, 29.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5430%\n",
      "Train Accuracy: 0.5073986162315035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:18<00:00, 33.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/60], Average Loss: 0.6944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:20<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5162%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [-1:58:45<00:00, -1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5209%\n",
      "Train Accuracy: 0.5069440937326397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:19<00:00, 32.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/60], Average Loss: 0.6933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:02<00:00, 27.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4990%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:03<00:00, 29.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5304%\n",
      "Train Accuracy: 0.512398363719004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:19<00:00, 32.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/60], Average Loss: 0.6928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:02<00:00, 27.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4873%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:03<00:00, 29.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5248%\n",
      "Train Accuracy: 0.5179031362052422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:20<00:00, 30.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/60], Average Loss: 0.6927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:20<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4691%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [-1:58:45<00:00, -1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5015%\n",
      "Train Accuracy: 0.5197717287005706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 474/619 [01:34<00:04, 31.55it/s] "
     ]
    }
   ],
   "source": [
    "\n",
    "from time import time\n",
    "\n",
    "model = GRU_Shallow_1fc_AntiOverfit(cfg, test_data.get_input_size())\n",
    "\n",
    "criterion = cfg.loss_func()\n",
    "optimizer = cfg.optimizer(model.parameters(), lr=cfg.LEARNING_RATE, weight_decay=1e-4)      #Added weight decay\n",
    "\n",
    "EPOCHS = cfg.EPOCHS\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "eval_accuracy_across_epochs = []\n",
    "train_accuracy_across_epochs = []\n",
    "test_accuracy_across_epochs = []\n",
    "loss_across_epochs = []\n",
    "training_time = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start_time = time()\n",
    "    epoch_loss = 0\n",
    "    total, correct = 0, 0\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(tqdm(train_dataloader)):\n",
    "        if isinstance(x, list):\n",
    "            x = [t.to(device) for t in x]\n",
    "            x = [t.float() for t in x]\n",
    "            y = y.to(device)\n",
    "        else:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            x = x.float()\n",
    "                #x = x.view(x.size(0), x.size(1), -1)  # Ensure input shape is (batch_size, seq_length, input_size)\n",
    "            x = x.view(x.size(0), -1)\n",
    "\n",
    "        outputs = model(x).squeeze()\n",
    "        #Extracting predictions to evaluate test set performance\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        \n",
    "\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Added Gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "         # Print progress\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            #print(f\"Epoch [{epoch+1}/{EPOCHS}], Step [{batch_idx+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}\")\n",
    "            pass\n",
    "\n",
    "    epoch_end_time = time()\n",
    "    training_time.append(epoch_end_time-epoch_start_time)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Average Loss: {epoch_loss/len(train_dataloader):.4f}\")\n",
    "\n",
    "    average_epoch_loss = epoch_loss/len(train_dataloader)\n",
    "    loss_across_epochs.append(average_epoch_loss)\n",
    "\n",
    "    #Get accuracy for each epoch on train and eval set\n",
    "    train_accuracy = correct/total\n",
    "    eval_accuracy, _, _, _ = evaluate_model(eval_dataloader, model)\n",
    "    test_accuracy, _, _, _ = evaluate_model(test_dataloader, model)\n",
    "    model.train()\n",
    "    print(f'Train Accuracy: {train_accuracy}')\n",
    "    print(f'Eval Accuracy: {eval_accuracy}')\n",
    "    print(f'Test Accuracy: {test_accuracy}')\n",
    "    train_accuracy_across_epochs.append(train_accuracy)\n",
    "    \n",
    "    eval_accuracy_across_epochs.append(eval_accuracy)\n",
    "\n",
    "    test_accuracy_across_epochs.append(test_accuracy)\n",
    "\n",
    "total_training_time = sum(training_time)\n",
    "h, rem = divmod(total_training_time, 3600)\n",
    "m, s = divmod(rem, 60)\n",
    "\n",
    "\n",
    "log_object = {\n",
    "    'Dataclass': type(train_data).__name__,\n",
    "    'Model': type(model).__name__,\n",
    "    'Report from Training': {\n",
    "        'training_time': f'{h}h {m}m {s}s',\n",
    "        'loss_across_epochs': loss_across_epochs,\n",
    "        'eval_accuracy_per_epoch': eval_accuracy_across_epochs,\n",
    "        'train_accuracy_per_epoch': train_accuracy_across_epochs,\n",
    "        'test_accuarcy_per_epoch': test_accuracy_across_epochs\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "\n",
    "\n",
    "test_accuracy, y, y_hat, y_hat_logits = evaluate_model(test_dataloader, model)\n",
    "accuracy_train, _, _, _ = evaluate_model(train_dataloader, model)\n",
    "accuracy_eval, _, _, _ = evaluate_model(eval_dataloader, model)\n",
    "\n",
    "\n",
    "F1 = f1_score(y, y_hat)\n",
    "precision = precision_score(y, y_hat)\n",
    "recall = recall_score(y, y_hat)\n",
    "\n",
    "log_object['Results'] = {\n",
    "    'accuracy_test': test_accuracy,\n",
    "    'accuracy_eval': accuracy_eval,\n",
    "    'accuracy_train': accuracy_train,\n",
    "    'F1_eval': F1,\n",
    "    'precision_eval': precision,\n",
    "    'recall_eval': recall,\n",
    "    'y_eval': y.tolist(),\n",
    "    'y_hat_eval': y_hat.tolist(),\n",
    "    'y_hat_logits_eval': y_hat_logits.tolist()\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log_to_file(experiment_name:str, log_obj:dict):\n",
    "    '''experiment_name is the name the file will be stored with. Suggested as f\"model_{model_class}_dataset_{dataset_class}\". The name gets \"_{id}.json\" appended'''\n",
    "    root = 'results_final_day/'\n",
    "    result_dir = os.path.join(root, experiment_name)\n",
    "\n",
    "    if not result_dir.split('/')[-1] in os.listdir(root):\n",
    "        os.makedirs(result_dir)\n",
    "\n",
    "    #Create new id with 4 digits incrementally\n",
    "    dir_ids = [int(path.split(\".\")[-2].split('_')[0]) for path in os.listdir(result_dir)]\n",
    "    new_id = str(max(dir_ids)+ 1) if len(dir_ids) > 0 else '0'     #Increment max id by 1 or set to 0 if no id present\n",
    "    id = '0'*(4-len(new_id)) + new_id    #Make id 4 digits\n",
    "\n",
    "    target_file = os.path.join(result_dir, f'{id}.json')\n",
    "    with open(target_file, 'w') as f:\n",
    "        json.dump(log_obj, f, indent=4)\n",
    "    \n",
    "    return target_file\n",
    "\n",
    "import inspect\n",
    "def log_config(log_object, config):\n",
    "    config_to_log = {}\n",
    "    for key, value in vars(config).items():\n",
    "        #print(key, inspect.isclass(value), inspect.isfunction(value))\n",
    "        if inspect.isclass(value) or inspect.isfunction(value): #or isinstance(value, types.FunctionType):  # Check if it's a class instance\n",
    "            config_to_log[key] = value.__name__  # Log the class name\n",
    "            #print(config_to_log[key])\n",
    "        elif isinstance(value, np.ndarray):\n",
    "            config_to_log[key] = value.tolist()\n",
    "        else:\n",
    "            config_to_log[key] = value  # Log the value directly for primitive types\n",
    "    log_object['Config'] = config_to_log\n",
    "    #Rearrange dict so config comes after dataset and model\n",
    "    log_object = {k: log_object[k] for k in list(log_object.keys())[:2] + ['Config'] + list(log_object.keys())[2:-1]}\n",
    "    return log_object\n",
    "\n",
    "\n",
    "log_object = log_config(log_object, cfg)\n",
    "\n",
    "created_file_path = write_log_to_file(f\"model_{type(model).__name__}_dataset_{type(train_data).__name__}\", log_object)\n",
    "\n",
    "from result_dataprocessing import generate_training_plot_from_file\n",
    "\n",
    "generate_training_plot_from_file(created_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
