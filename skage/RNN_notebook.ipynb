{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initalise dataset and config object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import cfg\n",
    "from dataset_loaders import TweetXPriceY, SentimentPriceXPriceY\n",
    "\n",
    "\n",
    "train_data = SentimentPriceXPriceY(start_date=cfg.train_start_date, \n",
    "                          end_date=cfg.train_end_date, \n",
    "                          **cfg.dataset_loader_args\n",
    "                          )\n",
    "\n",
    "eval_data = SentimentPriceXPriceY(start_date=cfg.eval_start_date, \n",
    "                         end_date=cfg.eval_end_date, \n",
    "                         **cfg.dataset_loader_args\n",
    "                         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_data, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "inspect_dataset = False\n",
    "if inspect_dataset:\n",
    "        for batch_idx, (x, y) in enumerate(tqdm(train_dataloader)):\n",
    "                input(f'Length train set: {train_data.__len__()}, Length Eval set: {eval_data.__len__()}')\n",
    "                print(f\"Sentiment batch shape: {x[0].size()}\")\n",
    "                print(f\"Price Feature batch shape: {x[1].size()}\")\n",
    "                print(f\"Labels batch shape: {y.size()}\")\n",
    "                print(x[0], x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class RNN_simple(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(RNN_simple, self).__init__()\n",
    "        #self.embedding = nn.Embedding(cfg.vocab_size, embedding_dim=50)\n",
    "        self.rnn = nn.RNN(input_size=cfg.dataset_loader_args['tweets_per_day']*cfg.dataset_loader_args['words_per_tweet'], hidden_size=cfg.rnn_hidden_size, num_layers=cfg.rnn_hidden_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(cfg.rnn_hidden_size, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = self.embedding(x)\n",
    "        h0 = torch.zeros(cfg.rnn_hidden_layers, x.size(0), cfg.rnn_hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out[:, -1, :]  # Use the output from the last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "class RNN_simple_v2(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(RNN_simple, self).__init__()\n",
    "        #self.embedding = nn.Embedding(cfg.vocab_size, embedding_dim=50)\n",
    "        self.rnn = nn.RNN(input_size=cfg.dataset_loader_args['tweets_per_day']*cfg.dataset_loader_args['words_per_tweet'], hidden_size=cfg.rnn_hidden_size, num_layers=cfg.rnn_hidden_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(cfg.rnn_hidden_size, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = self.embedding(x)\n",
    "        h0 = torch.zeros(cfg.rnn_hidden_layers, x.size(0), cfg.rnn_hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out[:, -1, :]  # Use the output from the last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class LSTM_v1(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(LSTM_v1, self).__init__()\n",
    "        #self.embedding = nn.Embedding(cfg.vocab_size, embedding_dim=50)\n",
    "        self.embedding = nn.Embedding(cfg.vocab_size, embedding_dim=128, padding_idx=0)\n",
    "        #self.rnn = nn.LSTM(input_size=cfg.dataset_loader_args['tweets_per_day']*cfg.dataset_loader_args['words_per_tweet'], hidden_size=cfg.rnn_hidden_size, num_layers=cfg.rnn_hidden_layers, batch_first=True)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=128,  # Embedding dimension\n",
    "            hidden_size=cfg.rnn_hidden_size, \n",
    "            num_layers=cfg.rnn_hidden_layers, \n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(cfg.rnn_hidden_size, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        x = self.embedding(x)  # Shape: (batch_size, seq_length, embedding_dim)\n",
    "        out, _ = self.lstm(x)  # Shape: (batch_size, seq_length, hidden_size)\n",
    "        out = self.dropout(out[:, -1, :])  # Use the output from the last time step\n",
    "        out = self.fc(out)  # Shape: (batch_size, 2)\n",
    "        return out  # Raw logits\n",
    "    \n",
    "\n",
    "from models import Two_Layer_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def evaluate_model(dataloader, model):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_logits = []\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, y) in enumerate(tqdm(dataloader)):\n",
    "            if isinstance(x, list):\n",
    "                x = [t.to(device) for t in x]\n",
    "                x = [t.float() for t in x]\n",
    "                y = y.to(device)\n",
    "            else:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "                x = x.float()\n",
    "                    #x = x.view(x.size(0), x.size(1), -1)  # Ensure input shape is (batch_size, seq_length, input_size)\n",
    "                x = x.view(x.size(0), -1)\n",
    "\n",
    "            outputs = model(x).squeeze()\n",
    "\n",
    "            outputs = model(x)  # Outputs are raw logits of shape (batch_size, num_classes)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            \n",
    "\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "\n",
    "            # Collect data for debugging\n",
    "            all_logits.append(outputs.cpu())\n",
    "            all_preds.append(predicted.cpu())\n",
    "            all_targets.append(y.cpu())\n",
    "\n",
    "    accuracy = correct / total\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}%')\n",
    "\n",
    "    # Concatenate all the collected and transform to numpy array\n",
    "    y_hat_logits = torch.cat(all_logits).numpy()\n",
    "    y_hat = torch.cat(all_preds).numpy()\n",
    "    y = torch.cat(all_targets).numpy()\n",
    "\n",
    "    return  accuracy, y, y_hat, y_hat_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [01:27<00:00,  7.08it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Average Loss: 0.6933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494/494 [01:03<00:00,  7.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5174%\n",
      "Train Accuracy: 0.5067925862330185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [01:27<00:00,  7.11it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Average Loss: 0.6933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494/494 [01:03<00:00,  7.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5174%\n",
      "Train Accuracy: 0.5032069087419827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [01:24<00:00,  7.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Average Loss: 0.6932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494/494 [01:02<00:00,  7.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5174%\n",
      "Train Accuracy: 0.5083581637291046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [01:25<00:00,  7.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Average Loss: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494/494 [01:03<00:00,  7.72it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5174%\n",
      "Train Accuracy: 0.5082066562294834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [01:26<00:00,  7.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Average Loss: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494/494 [01:02<00:00,  7.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5174%\n",
      "Train Accuracy: 0.5074996212312509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 564/619 [01:17<00:07,  7.25it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m total, correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_dataloader)):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     25\u001b[0m         x \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m x]\n",
      "File \u001b[0;32m/home/skage/miniconda3/envs/StockNet/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/home/skage/miniconda3/envs/StockNet/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/home/skage/miniconda3/envs/StockNet/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/home/skage/miniconda3/envs/StockNet/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/home/skage/projects/ikt450_deep-neural-networks/stocknet-project-ikt450/skage/dataset_loaders.py:256\u001b[0m, in \u001b[0;36mSentimentPriceXPriceY.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# Load price data and extract trading dates\u001b[39;00m\n\u001b[1;32m    255\u001b[0m price_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprice_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m--> 256\u001b[0m price_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(price_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    257\u001b[0m trading_dates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(price_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# Get previous T trading days\u001b[39;00m\n",
      "File \u001b[0;32m/home/skage/miniconda3/envs/StockNet/lib/python3.12/site-packages/pandas/core/frame.py:4078\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4071\u001b[0m \u001b[38;5;66;03m# GH#45316 Return view if key is not duplicated\u001b[39;00m\n\u001b[1;32m   4072\u001b[0m \u001b[38;5;66;03m# Only use drop_duplicates with duplicates for performance\u001b[39;00m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   4074\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[1;32m   4075\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4076\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdrop_duplicates(keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   4077\u001b[0m ):\n\u001b[0;32m-> 4078\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_cache(key)\n\u001b[1;32m   4080\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_mi \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m   4081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n",
      "File \u001b[0;32m/home/skage/miniconda3/envs/StockNet/lib/python3.12/site-packages/pandas/core/frame.py:4639\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4635\u001b[0m     \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[1;32m   4636\u001b[0m     \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[1;32m   4638\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(item)\n\u001b[0;32m-> 4639\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(loc, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4641\u001b[0m     cache[item] \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m   4643\u001b[0m     \u001b[38;5;66;03m# for a chain\u001b[39;00m\n",
      "File \u001b[0;32m/home/skage/miniconda3/envs/StockNet/lib/python3.12/site-packages/pandas/core/frame.py:4010\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   4006\u001b[0m \u001b[38;5;66;03m# icol\u001b[39;00m\n\u001b[1;32m   4007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4008\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[i]\n\u001b[0;32m-> 4010\u001b[0m     col_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39miget(i)\n\u001b[1;32m   4011\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_box_col_values(col_mgr, i)\n\u001b[1;32m   4013\u001b[0m     \u001b[38;5;66;03m# this is a cached value, mark it so\u001b[39;00m\n",
      "File \u001b[0;32m/home/skage/miniconda3/envs/StockNet/lib/python3.12/site-packages/pandas/core/internals/managers.py:1017\u001b[0m, in \u001b[0;36mBlockManager.iget\u001b[0;34m(self, i, track_ref)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;124;03mReturn the data as a SingleBlockManager.\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m block \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblknos[i]]\n\u001b[0;32m-> 1017\u001b[0m values \u001b[38;5;241m=\u001b[39m block\u001b[38;5;241m.\u001b[39miget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblklocs[i])\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;66;03m# shortcut for select a single-dim from a 2-dim BM\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(values)))\n",
      "File \u001b[0;32m/home/skage/miniconda3/envs/StockNet/lib/python3.12/site-packages/pandas/core/internals/managers.py:196\u001b[0m, in \u001b[0;36mBaseBlockManager.blklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rebuild_blknos_and_blklocs()\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blknos\n\u001b[0;32m--> 196\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mblklocs\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp]:\n\u001b[1;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    See blknos.__doc__\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# Note: these can be altered by other BlockManager methods.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from time import time\n",
    "\n",
    "model = Two_Layer_LSTM(cfg)\n",
    "\n",
    "criterion = cfg.loss_func()\n",
    "optimizer = cfg.optimizer(model.parameters(), lr=cfg.LEARNING_RATE)\n",
    "\n",
    "EPOCHS = cfg.EPOCHS\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "eval_accuracy_across_epochs = []\n",
    "train_accuracy_across_epochs = []\n",
    "loss_across_epochs = []\n",
    "training_time = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start_time = time()\n",
    "    epoch_loss = 0\n",
    "    total, correct = 0, 0\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(tqdm(train_dataloader)):\n",
    "        if isinstance(x, list):\n",
    "            x = [t.to(device) for t in x]\n",
    "            x = [t.float() for t in x]\n",
    "            y = y.to(device)\n",
    "        else:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            x = x.float()\n",
    "                #x = x.view(x.size(0), x.size(1), -1)  # Ensure input shape is (batch_size, seq_length, input_size)\n",
    "            x = x.view(x.size(0), -1)\n",
    "\n",
    "        outputs = model(x).squeeze()\n",
    "        #Extracting predictions to evaluate test set performance\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "         # Print progress\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            #print(f\"Epoch [{epoch+1}/{EPOCHS}], Step [{batch_idx+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}\")\n",
    "            pass\n",
    "\n",
    "    epoch_end_time = time()\n",
    "    training_time.append(epoch_end_time-epoch_start_time)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Average Loss: {epoch_loss/len(train_dataloader):.4f}\")\n",
    "\n",
    "    average_epoch_loss = epoch_loss/len(train_dataloader)\n",
    "    loss_across_epochs.append(average_epoch_loss)\n",
    "\n",
    "    #Get accuracy for each epoch on train and eval set\n",
    "    train_accuracy = correct/total\n",
    "    eval_accuracy, _, _, _ = evaluate_model(eval_dataloader, model)\n",
    "    model.train()\n",
    "    print(f'Train Accuracy: {train_accuracy}')\n",
    "    train_accuracy_across_epochs.append(train_accuracy)\n",
    "    \n",
    "    eval_accuracy_across_epochs.append(eval_accuracy)\n",
    "\n",
    "total_training_time = sum(training_time)\n",
    "h, rem = divmod(total_training_time, 3600)\n",
    "m, s = divmod(rem, 60)\n",
    "\n",
    "\n",
    "log_object = {\n",
    "    'Dataclass': type(train_data).__name__,\n",
    "    'Model': type(model).__name__,\n",
    "    'Report from Training': {\n",
    "        'training_time': f'{h}h {m}m {s}s',\n",
    "        'loss_across_epochs': loss_across_epochs,\n",
    "        'eval_accuracy_per_epoch': eval_accuracy_across_epochs,\n",
    "        'train_accuracy_per_epoch': train_accuracy_across_epochs\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "\n",
    "\n",
    "accuracy_eval, y, y_hat, y_hat_logits = evaluate_model(eval_dataloader, model)\n",
    "accuracy_train, _, _, _ = evaluate_model(train_dataloader, model)\n",
    "\n",
    "F1 = f1_score(y, y_hat)\n",
    "precision = precision_score(y, y_hat)\n",
    "recall = recall_score(y, y_hat)\n",
    "\n",
    "log_object['Results'] = {\n",
    "    'accuracy_eval': accuracy_eval,\n",
    "    'accuracy_train': accuracy_train,\n",
    "    'F1_eval': F1,\n",
    "    'precision_eval': precision,\n",
    "    'recall_eval': recall,\n",
    "    'y_eval': y.tolist(),\n",
    "    'y_hat_eval': y_hat.tolist(),\n",
    "    'y_hat_logits_eval': y_hat_logits.tolist()\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log_to_file(experiment_name:str, log_obj:dict):\n",
    "    '''experiment_name is the name the file will be stored with. Suggested as f\"model_{model_class}_dataset_{dataset_class}\". The name gets \"_{id}.json\" appended'''\n",
    "    root = 'results/'\n",
    "    result_dir = os.path.join(root, experiment_name)\n",
    "\n",
    "    if not result_dir.split('/')[-1] in os.listdir(root):\n",
    "        os.makedirs(result_dir)\n",
    "\n",
    "    #Create new id with 4 digits incrementally\n",
    "    dir_ids = [int(path.split(\".\")[-2].split('_')[0]) for path in os.listdir(result_dir)]\n",
    "    new_id = str(max(dir_ids)+ 1) if len(dir_ids) > 0 else '0'     #Increment max id by 1 or set to 0 if no id present\n",
    "    id = '0'*(4-len(new_id)) + new_id    #Make id 4 digits\n",
    "\n",
    "    target_file = os.path.join(result_dir, f'{id}.json')\n",
    "    with open(target_file, 'w') as f:\n",
    "        json.dump(log_obj, f, indent=4)\n",
    "    \n",
    "    return target_file\n",
    "\n",
    "import inspect\n",
    "def log_config(log_object, config):\n",
    "    config_to_log = {}\n",
    "    for key, value in vars(config).items():\n",
    "        #print(key, inspect.isclass(value), inspect.isfunction(value))\n",
    "        if inspect.isclass(value) or inspect.isfunction(value): #or isinstance(value, types.FunctionType):  # Check if it's a class instance\n",
    "            config_to_log[key] = value.__name__  # Log the class name\n",
    "            #print(config_to_log[key])\n",
    "        elif isinstance(value, np.ndarray):\n",
    "            config_to_log[key] = value.tolist()\n",
    "        else:\n",
    "            config_to_log[key] = value  # Log the value directly for primitive types\n",
    "    log_object['Config'] = config_to_log\n",
    "    #Rearrange dict so config comes after dataset and model\n",
    "    log_object = {k: log_object[k] for k in list(log_object.keys())[:2] + ['Config'] + list(log_object.keys())[2:-1]}\n",
    "    return log_object\n",
    "\n",
    "\n",
    "log_object = log_config(log_object, cfg)\n",
    "\n",
    "created_file_path = write_log_to_file(f\"model_{type(model).__name__}_dataset_{type(train_data).__name__}\", log_object)\n",
    "\n",
    "from result_dataprocessing import generate_training_plot_from_file\n",
    "\n",
    "generate_training_plot_from_file(created_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
