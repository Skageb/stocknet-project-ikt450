{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258\n",
      "520\n",
      "          Date       Open       High        Low      Close  Adj Close  \\\n",
      "333 2014-01-02  26.170000  26.170000  25.780001  25.930000  22.476974   \n",
      "336 2014-01-07  25.709999  25.910000  25.680000  25.870001  22.424965   \n",
      "339 2014-01-10  26.100000  26.299999  26.070000  26.299999  22.797699   \n",
      "340 2014-01-13  26.230000  26.299999  26.040001  26.080000  22.607000   \n",
      "341 2014-01-14  26.260000  26.430000  26.160000  26.420000  22.901722   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "725 2015-07-24  20.360001  20.379999  19.969999  20.000000  18.578381   \n",
      "726 2015-07-27  19.889999  19.889999  19.639999  19.680000  18.281128   \n",
      "727 2015-07-28  19.709999  19.900000  19.670000  19.870001  18.457623   \n",
      "728 2015-07-29  19.809999  20.059999  19.799999  19.940001  18.522646   \n",
      "730 2015-07-31  20.389999  20.410000  20.250000  20.280001  18.838480   \n",
      "\n",
      "      Volume Name  Label  \n",
      "333  2720400  ABB      0  \n",
      "336   896200  ABB      1  \n",
      "339  1297500  ABB      1  \n",
      "340  1059600  ABB      0  \n",
      "341  1159500  ABB      1  \n",
      "..       ...  ...    ...  \n",
      "725  2708600  ABB      0  \n",
      "726  2211000  ABB      0  \n",
      "727  1868700  ABB      1  \n",
      "728  1413400  ABB      1  \n",
      "730  1517100  ABB      0  \n",
      "\n",
      "[159 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "missing_entries = 0\n",
    "\n",
    "def generate_label(open_price, close_price) -> int:\n",
    "    global missing_entries\n",
    "    movement_percent = (close_price - open_price) / open_price * 100\n",
    "    if movement_percent <= -0.5:\n",
    "        return 0\n",
    "    elif movement_percent >= 0.55:\n",
    "        return 1\n",
    "    else:\n",
    "        missing_entries += 1\n",
    "        return -1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dataset/price/raw/ABB.csv')\n",
    "path = 'dataset/price/raw/ABB.csv'\n",
    "\n",
    "stock_name = path.split('/')[-1].split('.')[0]\n",
    "\n",
    "df['Name'] = stock_name\n",
    "df['Label'] = df.apply(lambda row: generate_label(row['Open'], row['Close']), axis=1)\n",
    "print(len(df))\n",
    "\n",
    "df = df[~(df['Label'] == -1)]\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Define start and end dates\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2015-08-01'\n",
    "\n",
    "# Filter the DataFrame for dates between start_date and end_date\n",
    "filtered_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_train_data(path:str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    stock_name = path.split('.')[0]\n",
    "    if '/' in stock_name:\n",
    "        stock_name = stock_name.split('/')[-1]\n",
    "\n",
    "    df['Name'] = stock_name\n",
    "\n",
    "    df['Label'] = df.apply(lambda row: generate_label(row['Open'], row['Close']), axis=1)\n",
    "\n",
    "    df = df[~(df['Label'] == -1)]\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Define start and end dates\n",
    "    start_date = '2014-01-01'\n",
    "    end_date = '2015-08-02'\n",
    "\n",
    "    # Filter the DataFrame for dates between start_date and end_date\n",
    "    filtered_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "\n",
    "    return filtered_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17856\n",
      "52266\n",
      "          Date       Open       High        Low      Close  Adj Close  \\\n",
      "333 2014-01-02  23.340000  23.340000  23.030001  23.129999  19.080498   \n",
      "334 2014-01-03  23.230000  23.330000  23.030001  23.110001  19.064001   \n",
      "335 2014-01-06  23.059999  23.219999  22.850000  22.920000  18.907265   \n",
      "338 2014-01-09  22.910000  23.209999  22.129999  22.350000  18.437057   \n",
      "340 2014-01-13  22.080000  22.350000  22.080000  22.260000  18.362814   \n",
      "\n",
      "       Volume  Name  Label  \n",
      "333  294200.0  BSAC      0  \n",
      "334  204800.0  BSAC      0  \n",
      "335  257200.0  BSAC      0  \n",
      "338  422500.0  BSAC      0  \n",
      "340  286100.0  BSAC      1  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "missing_entries = 0\n",
    "root = 'dataset/price/raw'\n",
    "for idx, stock_path in enumerate(os.listdir(root)):\n",
    "    df_stock = get_train_data(os.path.join(root, stock_path))\n",
    "    if idx == 0:\n",
    "        df_train = df_stock\n",
    "    else:\n",
    "        df_train = pd.concat([df_train, df_stock])\n",
    "    \n",
    "print(len(df_train))\n",
    "print(missing_entries)\n",
    "print(df_train.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date       Open       High        Low      Close  Adj Close   Volume  \\\n",
      "0 2012-09-13  19.209999  19.570000  19.110001  19.469999  16.341057  4038700   \n",
      "1 2012-09-19  19.629999  19.860001  19.530001  19.780001  16.601238  1928400   \n",
      "2 2012-09-20  19.370001  19.530001  19.309999  19.480000  16.349445  1553200   \n",
      "3 2012-09-21  19.700001  19.709999  19.480000  19.500000  16.366238  1532400   \n",
      "4 2012-09-25  19.379999  19.420000  19.030001  19.030001  15.971768  1467400   \n",
      "\n",
      "  Name  Label  Open_t_minus_5  Close_t_minus_5  Open_t_minus_4  \\\n",
      "0  ABB      1       17.340000        17.240000       17.219999   \n",
      "1  ABB      1       17.219999        17.320000       17.690001   \n",
      "2  ABB      1       17.690001        17.910000       18.760000   \n",
      "3  ABB      0       18.760000        18.540001       18.719999   \n",
      "4  ABB      0       18.719999        18.900000       19.209999   \n",
      "\n",
      "   Close_t_minus_4  Open_t_minus_3  Close_t_minus_3  Open_t_minus_2  \\\n",
      "0        17.320000       17.690001        17.910000       18.760000   \n",
      "1        17.910000       18.760000        18.540001       18.719999   \n",
      "2        18.540001       18.719999        18.900000       19.209999   \n",
      "3        18.900000       19.209999        19.469999       19.629999   \n",
      "4        19.469999       19.629999        19.780001       19.370001   \n",
      "\n",
      "   Close_t_minus_2  Open_t_minus_1  Close_t_minus_1  \n",
      "0        18.540001       18.719999        18.900000  \n",
      "1        18.900000       19.209999        19.469999  \n",
      "2        19.469999       19.629999        19.780001  \n",
      "3        19.780001       19.370001        19.480000  \n",
      "4        19.480000       19.700001        19.500000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10218/2783819110.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('Name').apply(create_lagged_features)\n"
     ]
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values(['Name', 'Date']).reset_index(drop=True)\n",
    "\n",
    "lag = 5\n",
    "\n",
    "lagged_columns = []\n",
    "def create_lagged_features(group):\n",
    "    for i in range(lag, 0, -1):\n",
    "        group[f'Open_t_minus_{i}'] = group['Open'].shift(i)\n",
    "        group[f'Close_t_minus_{i}'] = group['Close'].shift(i)\n",
    "        # Append only if columns are new to avoid duplicates\n",
    "        if f'Open_t_minus_{i}' not in lagged_columns:\n",
    "            lagged_columns.append(f'Open_t_minus_{i}')\n",
    "        if f'Close_t_minus_{i}' not in lagged_columns:\n",
    "            lagged_columns.append(f'Close_t_minus_{i}')\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group\n",
    "df = df.groupby('Name').apply(create_lagged_features)\n",
    "\n",
    "# Drop rows with NaN values in any of the lagged columns\n",
    "df = df.dropna(subset=lagged_columns).reset_index(drop=True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train\n",
    "\n",
    "lag = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       78.980003 77.28286  76.778572 77.704285 77.760002 77.148575\n",
      " 76.972855 77.637146 78.114288 76.645714]\n",
      "0\n",
      "        Date  Name   Open_t-5  Close_t-5   Open_t-4  Close_t-4   Open_t-3  \\\n",
      "0 2014-01-10     0  78.980003  77.282860  76.778572  77.704285  77.760002   \n",
      "1 2014-01-13     0  76.778572  77.704285  77.760002  77.148575  76.972855   \n",
      "2 2014-01-14     0  77.760002  77.148575  76.972855  77.637146  78.114288   \n",
      "3 2014-01-15     0  76.972855  77.637146  78.114288  76.645714  77.118568   \n",
      "4 2014-01-17     0  78.114288  76.645714  77.118568  76.134285  75.701431   \n",
      "\n",
      "   Close_t-3   Open_t-2  Close_t-2   Open_t-1  Close_t-1  Label  \n",
      "0  77.148575  76.972855  77.637146  78.114288  76.645714      0  \n",
      "1  77.637146  78.114288  76.645714  77.118568  76.134285      1  \n",
      "2  76.645714  77.118568  76.134285  75.701431  76.532860      1  \n",
      "3  76.134285  75.701431  76.532860  76.888573  78.055717      1  \n",
      "4  76.532860  76.888573  78.055717  79.074287  79.622856      0  \n",
      "17856 17421\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def create_rnn_input(df):\n",
    "    # Ensure 'Date' column is in datetime format\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Sort the DataFrame by 'Name' and 'Date'\n",
    "    df = df.sort_values(['Name', 'Date']).reset_index(drop=True)\n",
    "\n",
    "    # List to store the new rows\n",
    "    data_rows = []\n",
    "\n",
    "    name_encoder = LabelEncoder()\n",
    "    df['Name'] = name_encoder.fit_transform(df['Name'])\n",
    "\n",
    "    # Group the DataFrame by 'Name' (stock)\n",
    "    grouped = df.groupby('Name')\n",
    "\n",
    "    # For each stock group\n",
    "    for name, group in grouped:\n",
    "        group = group.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "        # Skip if the group has less than 6 rows (need at least 5 days of history)\n",
    "        if len(group) < 6:\n",
    "            continue\n",
    "\n",
    "        # Iterate over the group starting from the 5th index\n",
    "        for idx in range(5, len(group)):\n",
    "            # Get the previous 5 trading days\n",
    "            prev_data = group.iloc[idx-5:idx]\n",
    "\n",
    "            # Prepare the row data\n",
    "            row_dict = {'Date': group.loc[idx, 'Date'], 'Name': name}\n",
    "\n",
    "            # Add Open and Close prices from previous 5 trading days\n",
    "            for i in range(5):\n",
    "                row_dict[f'Open_t-{5-i}'] = prev_data.iloc[i]['Open']\n",
    "                row_dict[f'Close_t-{5-i}'] = prev_data.iloc[i]['Close']\n",
    "\n",
    "            # Add the Label for the target date\n",
    "            row_dict['Label'] = group.loc[idx, 'Label']\n",
    "\n",
    "            # Append the row to data_rows\n",
    "            data_rows.append(row_dict)\n",
    "\n",
    "    # Create a new DataFrame from data_rows\n",
    "    new_df = pd.DataFrame(data_rows)\n",
    "\n",
    "    x = new_df.drop(['Label', 'Date'], axis=1)\n",
    "    y = new_df['Label']\n",
    "    x = x.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "\n",
    "    return x, y\n",
    "\n",
    "new_df = create_rnn_input(df)\n",
    "print(new_df.head())\n",
    "print(len(df), len(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
