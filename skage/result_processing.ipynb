{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON from file /home/skage/projects/ikt450_deep-neural-networks/stocknet-project-ikt450/skage/results/price_history_only_0001.json: Expecting value: line 27 column 19 (char 710)\n",
      "                                             file_name              Model  \\\n",
      "93   model_Depth_First_GRU2_dataset_NormSentimentAl...   Depth_First_GRU2   \n",
      "74   model_Shallow_First_GRU_dataset_TwitterSentime...  Shallow_First_GRU   \n",
      "90   model_Depth_First_GRU2_dataset_NormSentimentAl...   Depth_First_GRU2   \n",
      "3    model_GRU_Deep_dataset_TwitterSentimentVolumeP...           GRU_Deep   \n",
      "16   model_Two_Layer_LSTM_dataset_SentimentPriceXPr...     Two_Layer_LSTM   \n",
      "..                                                 ...                ...   \n",
      "110       model_LSTM_v1_dataset_TweetXPriceY/0012.json            LSTM_v1   \n",
      "111       model_LSTM_v1_dataset_TweetXPriceY/0015.json            LSTM_v1   \n",
      "112       model_LSTM_v1_dataset_TweetXPriceY/0007.json            LSTM_v1   \n",
      "113       model_LSTM_v1_dataset_TweetXPriceY/0013.json            LSTM_v1   \n",
      "114       model_LSTM_v1_dataset_TweetXPriceY/0014.json            LSTM_v1   \n",
      "\n",
      "                              Dataclass  Results Testset.accuracy_test  \\\n",
      "93         NormSentimentAllPriceXPriceY                       0.558298   \n",
      "74   TwitterSentimentVolumePriceXPriceY                       0.531017   \n",
      "90         NormSentimentAllPriceXPriceY                       0.529393   \n",
      "3    TwitterSentimentVolumePriceXPriceY                       0.528094   \n",
      "16                SentimentPriceXPriceY                       0.528094   \n",
      "..                                  ...                            ...   \n",
      "110                        TweetXPriceY                            NaN   \n",
      "111                        TweetXPriceY                            NaN   \n",
      "112                        TweetXPriceY                            NaN   \n",
      "113                        TweetXPriceY                            NaN   \n",
      "114                        TweetXPriceY                            NaN   \n",
      "\n",
      "     Results Testset.F1_test  Results Testset.MCC_test  \\\n",
      "93                  0.337232                  0.104081   \n",
      "74                  0.164352                  0.027889   \n",
      "90                  0.005491                  0.038154   \n",
      "3                   0.000000                  0.000000   \n",
      "16                  0.000000                  0.000000   \n",
      "..                       ...                       ...   \n",
      "110                      NaN                       NaN   \n",
      "111                      NaN                       NaN   \n",
      "112                      NaN                       NaN   \n",
      "113                      NaN                       NaN   \n",
      "114                      NaN                       NaN   \n",
      "\n",
      "     Results Testset.precision_test  Results Testset.recall_test  \n",
      "93                         0.577629                     0.238128  \n",
      "74                         0.516364                     0.097729  \n",
      "90                         1.000000                     0.002753  \n",
      "3                          0.000000                     0.000000  \n",
      "16                         0.000000                     0.000000  \n",
      "..                              ...                          ...  \n",
      "110                             NaN                          NaN  \n",
      "111                             NaN                          NaN  \n",
      "112                             NaN                          NaN  \n",
      "113                             NaN                          NaN  \n",
      "114                             NaN                          NaN  \n",
      "\n",
      "[130 rows x 8 columns]\n",
      "All cols: Index(['Dataclass', 'Model', 'Config.train_start_date',\n",
      "       'Config.train_end_date', 'Config.eval_start_date',\n",
      "       'Config.eval_end_date', 'Config.test_start_date',\n",
      "       'Config.test_end_date', 'Config.loss_func', 'Config.optimizer',\n",
      "       'Config.model', 'Config.dataloader', 'Config.weighted_loss',\n",
      "       'Config.EPOCHS', 'Config.BATCH_SIZE', 'Config.num_workers',\n",
      "       'Config.LEARNING_RATE', 'Config.vocab_size', 'Config.vocab_method',\n",
      "       'Config.rnn_hidden_size', 'Config.rnn_hidden_layers',\n",
      "       'Config.dataset_loader_args.twitter_root',\n",
      "       'Config.dataset_loader_args.price_root',\n",
      "       'Config.dataset_loader_args.day_lag',\n",
      "       'Config.dataset_loader_args.tweets_per_day',\n",
      "       'Config.dataset_loader_args.words_per_tweet',\n",
      "       'Config.dataset_loader_args.sentiment_model',\n",
      "       'Report from Training.training_time',\n",
      "       'Report from Training.loss_across_epochs.mean',\n",
      "       'Report from Training.loss_across_epochs.min',\n",
      "       'Report from Training.loss_across_epochs.max',\n",
      "       'Report from Training.loss_across_epochs.last',\n",
      "       'Report from Training.eval_accuracy_per_epoch.mean',\n",
      "       'Report from Training.eval_accuracy_per_epoch.min',\n",
      "       'Report from Training.eval_accuracy_per_epoch.max',\n",
      "       'Report from Training.eval_accuracy_per_epoch.last',\n",
      "       'Report from Training.train_accuracy_per_epoch.mean',\n",
      "       'Report from Training.train_accuracy_per_epoch.min',\n",
      "       'Report from Training.train_accuracy_per_epoch.max',\n",
      "       'Report from Training.train_accuracy_per_epoch.last',\n",
      "       'Results Testset.accuracy_test', 'Results Testset.accuracy_train',\n",
      "       'Results Testset.accuracy_eval', 'Results Testset.F1_test',\n",
      "       'Results Testset.MCC_test', 'Results Testset.precision_test',\n",
      "       'Results Testset.recall_test', 'Results Testset.y_test.mean',\n",
      "       'Results Testset.y_test.min', 'Results Testset.y_test.max',\n",
      "       'Results Testset.y_test.last', 'Results Testset.y_hat_test.mean',\n",
      "       'Results Testset.y_hat_test.min', 'Results Testset.y_hat_test.max',\n",
      "       'Results Testset.y_hat_test.last',\n",
      "       'Results Testset.y_hat_logits_test.length', 'file_name',\n",
      "       'Results.accuracy_eval', 'Results.accuracy_train', 'Results.F1_eval',\n",
      "       'Results.precision_eval', 'Results.recall_eval', 'Results.y_eval.mean',\n",
      "       'Results.y_eval.min', 'Results.y_eval.max', 'Results.y_eval.last',\n",
      "       'Results.y_hat_eval.mean', 'Results.y_hat_eval.min',\n",
      "       'Results.y_hat_eval.max', 'Results.y_hat_eval.last',\n",
      "       'Results.y_hat_logits_eval.length', 'Config.fc_hidden_size',\n",
      "       'Config.recurrent_layers'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def flatten_json(y):\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name=''):\n",
    "        if isinstance(x, dict):\n",
    "            for a in x:\n",
    "                flatten(x[a], f'{name}{a}.')\n",
    "        elif isinstance(x, list):\n",
    "            # Handle lists by extracting summary statistics if they contain numbers\n",
    "            if len(x) == 0:\n",
    "                out[name[:-1]] = None\n",
    "            elif all(isinstance(i, (int, float)) for i in x):\n",
    "                out[name + 'mean'] = sum(x) / len(x)\n",
    "                out[name + 'min'] = min(x)\n",
    "                out[name + 'max'] = max(x)\n",
    "                out[name + 'last'] = x[-1]\n",
    "            else:\n",
    "                # Store the length of the list for non-numeric lists\n",
    "                out[name + 'length'] = len(x)\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(y)\n",
    "    return out\n",
    "\n",
    "def load_results_to_dataframe(results_dir):\n",
    "    data_list = []\n",
    "    for root, dirs, files in os.walk(results_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                json_path = os.path.join(root, file)\n",
    "                with open(json_path, 'r') as f:\n",
    "                    try:\n",
    "                        data = json.load(f)\n",
    "                        flat_data = flatten_json(data)\n",
    "                        flat_data['file_name'] = os.path.join(root.split('/')[-1], file)\n",
    "                        data_list.append(flat_data)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Error decoding JSON from file {json_path}: {e}\")\n",
    "    df = pd.DataFrame(data_list)\n",
    "    return df\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    results_dir = '/home/skage/projects/ikt450_deep-neural-networks/stocknet-project-ikt450/skage/results'  # Replace with your actual path\n",
    "    df = load_results_to_dataframe(results_dir)\n",
    "    \n",
    "\n",
    "    # Select relevant columns\n",
    "    columns_of_interest = [\n",
    "        'file_name',\n",
    "        'Model',\n",
    "        'Dataclass',\n",
    "        'Results Testset.accuracy_test',\n",
    "        'Results Testset.F1_test',\n",
    "        'Results Testset.MCC_test',\n",
    "        'Results Testset.precision_test',\n",
    "        'Results Testset.recall_test'\n",
    "    ]\n",
    "    # Keep only the columns that are present in the DataFrame\n",
    "    columns_present = [col for col in columns_of_interest if col in df.columns]\n",
    "    df_selected = df[columns_present]\n",
    "    \n",
    "    # Sort by test accuracy in descending order\n",
    "    df_sorted = df_selected.sort_values(by='Results Testset.accuracy_test', ascending=False)\n",
    "    \n",
    "    # Display the sorted DataFrame\n",
    "    print(df_sorted)\n",
    "\n",
    "    print('All keys:', df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
